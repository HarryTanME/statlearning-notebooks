{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8: Decision Trees ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import Image\n",
    "import StringIO, pydot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>Bad</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>Good</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>Medium</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>Bad</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120       Bad   42   \n",
       "1  11.22        111      48           16         260     83      Good   65   \n",
       "2  10.06        113      35           10         269     80    Medium   59   \n",
       "3   7.40        117     100            4         466     97    Medium   55   \n",
       "4   4.15        141      64            3         340    128       Bad   38   \n",
       "\n",
       "   Education Urban   US  \n",
       "0         17   Yes  Yes  \n",
       "1         10   Yes  Yes  \n",
       "2         12   Yes  Yes  \n",
       "3         14   Yes  Yes  \n",
       "4         13   Yes   No  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carseats_df = pd.read_csv(\"../data/Carseats.csv\")\n",
    "carseats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  6.,  16.,  47.,  83.,  89.,  79.,  40.,  29.,   8.,   3.]),\n",
       " array([  0.   ,   1.627,   3.254,   4.881,   6.508,   8.135,   9.762,\n",
       "         11.389,  13.016,  14.643,  16.27 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe927190dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert other string variables to numeric\n",
    "carseats_df[\"ShelveLoc\"] = pd.factorize(carseats_df[\"ShelveLoc\"])[0]\n",
    "carseats_df[\"Urban\"] = pd.factorize(carseats_df[\"Urban\"])[0]\n",
    "carseats_df[\"US\"] = pd.factorize(carseats_df[\"US\"])[0]\n",
    "# We want to add a binary response variable High (High Sales). We build a histogram to \n",
    "# determine the cut point.\n",
    "plt.hist(carseats_df[\"Sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "      <th>High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price  ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120          0   42   \n",
       "1  11.22        111      48           16         260     83          1   65   \n",
       "2  10.06        113      35           10         269     80          2   59   \n",
       "3   7.40        117     100            4         466     97          2   55   \n",
       "4   4.15        141      64            3         340    128          0   38   \n",
       "\n",
       "   Education  Urban  US  High  \n",
       "0         17      0   0     1  \n",
       "1         10      0   0     1  \n",
       "2         12      0   0     1  \n",
       "3         14      0   0     0  \n",
       "4         13      0   1     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a binary response variable HighSales and add to dataframe\n",
    "carseats_df[\"High\"] = carseats_df[\"Sales\"].map(lambda x: 0 if x <= 8 else 1)\n",
    "carseats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "\"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-705bc02b22c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/py27/lib/python2.7/site-packages/pydot.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, prog)\u001b[0m\n\u001b[1;32m   1679\u001b[0m                 \u001b[0;34m'create_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m                 \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m                     self.create(format=f, prog=prog))\n\u001b[0m\u001b[1;32m   1682\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m             f.__doc__ = (\n",
      "\u001b[0;32m/opt/conda/envs/py27/lib/python2.7/site-packages/pydot.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1881\u001b[0m                 raise Exception(\n\u001b[1;32m   1882\u001b[0m                     '\"{prog}\" not found in path.'.format(\n\u001b[0;32m-> 1883\u001b[0;31m                         prog=prog))\n\u001b[0m\u001b[1;32m   1884\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: \"dot\" not found in path."
     ]
    }
   ],
   "source": [
    "# fit a decision tree to predict High from the data. We remove Sales because High is\n",
    "# derived from Sales and is thus correlated to the response\n",
    "collist = [x for x in carseats_df.columns if x not in ('Sales', 'High')]\n",
    "clf = DecisionTreeClassifier()\n",
    "X = carseats_df[collist].values\n",
    "y = carseats_df[\"High\"].values\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Visualize tree\n",
    "dot_data = StringIO.StringIO()\n",
    "export_graphviz(clf, out_file=dot_data)\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph[0].create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build the diagram above, I had to install pydot. I had some problems with pyparsing version mismatch which is described [here](http://stackoverflow.com/questions/15951748/pydot-and-graphviz-error-couldnt-import-dot-parser-loading-of-dot-files-will). The solution involved manually hacking the dot_parser.py file as [described here](https://code.google.com/p/pydot/issues/detail?id=81#c9).\n",
    "\n",
    "One can also build a text representation of the tree using [ideas from this](http://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree) and [this](http://stackoverflow.com/questions/20156951/how-do-i-find-which-attributes-my-tree-splits-on-when-using-scikit-learn) Stack Overflow page.\n",
    "\n",
    "We evaluate a classifier by splitting our dataset into a 250/150 train/test set, training the tree on the training set and evaluating performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr, Xt, yr, yt = train_test_split(X, y, train_size=250, test_size=150, random_state=42)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(Xr, yr)\n",
    "ypred = clf.predict(Xt)\n",
    "(confusion_matrix(yt, ypred), accuracy_score(yt, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning can reduce overfitting. Scikit-Learn DecisionTree classifier does not support pruning currently, but one can set the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem. Here we will use cross validation with different max depths to optimize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(Xr.shape[0], n_folds=10)\n",
    "accs = []\n",
    "max_depths = range(1, 20)\n",
    "for max_depth in max_depths:\n",
    "    k_accs = []\n",
    "    for train, test in kfold:\n",
    "        Xtrain, Xtest, ytrain, ytest = Xr[train], Xr[test], yr[train], yr[test]\n",
    "        clf = DecisionTreeClassifier(max_depth=max_depth)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        ypred = clf.predict(Xtest)\n",
    "        k_accs.append(accuracy_score(ytest, ypred))\n",
    "    accs.append(np.mean(k_accs))\n",
    "# plot the accuracies as a function of max_depth\n",
    "plt.plot(max_depths, accs, linewidth=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest value of max_depth for which accuracy scores have reached a peak is around 7. We will now evaluate the \"best\" tree from cross validation against our held out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=7)\n",
    "clf.fit(Xr, yr)\n",
    "ypred = clf.predict(Xt)\n",
    "confusion_matrix(yt, ypred), accuracy_score(yt, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests ###\n",
    "\n",
    "Random Forests build lots of bushy trees, and then average them to reduce the variance. We will use Random Forests to predict medv (Median House Price in 1,000 dollars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df = pd.read_csv(\"../data/Boston.csv\")\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_df[boston_df.columns[:-1]].values\n",
    "y = boston_df[\"medv\"].values\n",
    "\n",
    "# Split into training and test sets\n",
    "Xr, Xt, yr, yt = train_test_split(X, y, train_size=300, test_size=202, random_state=42)\n",
    "\n",
    "# Train random forest\n",
    "reg = RandomForestRegressor(n_estimators=500, oob_score=True)\n",
    "reg.fit(Xr, yr)\n",
    "ypred = reg.predict(Xt)\n",
    "mean_squared_error(yt, ypred), reg.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to vary max_features (the number of features to consider when looking for the best split) from 1 to 13 and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_scores = []\n",
    "mses = []\n",
    "num_feats = range(1, 14)\n",
    "for num_feat in num_feats:\n",
    "    reg = RandomForestRegressor(n_estimators=500, max_features=num_feat, oob_score=True)\n",
    "    reg.fit(Xr, yr)\n",
    "    ypred = reg.predict(Xt)\n",
    "    mses.append(mean_squared_error(yt, ypred))\n",
    "    oob_scores.append(reg.oob_score_)\n",
    "plt.plot(num_feats, mses, color='b', linewidth=2.5)\n",
    "plt.plot(num_feats, oob_scores, color='r', linewidth=2.5)\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MSE (blue); OOB (red)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting ###\n",
    "\n",
    "Boosting builds lots of small trees. Unlike Random Forests, each tree tries to make up for the deficiencies in the current ensemble. With Boosting, the number of trees is a tuning parameter. Using the same train/test split, we plot the variance of MSE against the number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = range(100, 2000, 100)\n",
    "mses = []\n",
    "for num_tree in num_trees:\n",
    "    reg = GradientBoostingRegressor(n_estimators=num_tree)\n",
    "    reg.fit(Xr, yr)\n",
    "    ypred = reg.predict(Xt)\n",
    "    mses.append(mean_squared_error(yt, ypred))\n",
    "plt.plot(num_trees, mses)\n",
    "plt.xlabel(\"#-trees\")\n",
    "plt.ylabel(\"MSE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
